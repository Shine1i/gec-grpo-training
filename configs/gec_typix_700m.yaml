#########################################################
# GEC with moogin/typix-mixed-epo (LFM2-700M fine-tuned)
#########################################################

seed: 42

# Language Model
model_name: moogin/typix-grammar-small
max_seq_length: 512
system_prompt: |
  You are a grammatical error correction assistant.
  Correct any spelling and grammatical errors in the given text.
  Make minimal changes. Preserve the original meaning.
  Output only the corrected text, nothing else.

# Dataset (HuggingFace)
dataset_name: moogin/typix-hq-grannar
dataset_size: 1000  # null for full dataset

# Training hyperparameters
learning_rate: 5.0e-5
warmup_steps: 50
max_steps: 500

# vLLM inference
per_device_train_batch_size: 4
num_generations: 4
generation_batch_size: 4
max_completion_length: 256
use_vllm: true
vllm_mode: "colocate"
vllm_gpu_memory_utilization: 0.3

# Reward weights
greco_weight: 0.6
semantic_weight: 0.3
laziness_weight: 0.1

# Reward models (HuggingFace)
greco_model_name: mrqorib/grammaticality
mpnet_model: sentence-transformers/all-mpnet-base-v2

# LoRA configuration
use_peft: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
lora_bias: "none"
use_rslora: false
lora_target_modules:
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"
  - "gate_proj"
  - "up_proj"
  - "down_proj"

# Experiment tracking
wandb_enabled: true
wandb_project_name: "gec-fine-tune-with-grpo"
logging_steps: 10
push_to_hf: false
