#########################################################
# LFM2-350M with full fine-tuning for book-flight task
# NOTE: as per 2025-12-25 this example is not complete due to a bug in OpenEnv
#########################################################

seed: 23
# resume_from_checkpoint: null

# Language Model parameters
model_name: LiquidAI/LFM2-350M
max_seq_length: 2048
system_prompt: |
  You control a web browser through BrowserGym actions.
  You must complete the given web task by interacting with the page.

  Available actions:
  - noop() - Do nothing
  - click(bid) - Click element with BrowserGym ID (the number in brackets)
  - fill(bid, text) - Fill input field with text
  - send_keys(text) - Send keyboard input
  - scroll(direction) - Scroll up/down

  The page structure shows elements as: [bid] element_type 'element_text'
  For example: [13] button 'Click Me!' means bid='13'

  Reply with exactly ONE action on a single line, e.g.:
  click('13')
  fill('42', 'hello world')
  noop()

  Do not include explanations or multiple actions.

# BrowserGym environment
browsergym_url: https://burtenshaw-browsergym-v2.hf.space
dataset_size: 10
default_goal: Complete the web task successfully.

# How long and how aggressive do we train?
learning_rate: 5.0e-6
warmup_steps: 10

# Optimization
# gradient_checkpointing: true

# vLLM inference
per_device_train_batch_size: 1
num_generations: 2
generation_batch_size: 2
max_steps: 1
max_completion_length: 32
use_vllm: true
vllm_mode: "colocate"
vllm_gpu_memory_utilization: 0.1

# Experiment tracking
wandb_enabled: true
wandb_project_name: "browser-control-fine-tune-with-grpo"
logging_steps: 1
push_to_hf: false
