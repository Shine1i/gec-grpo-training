#########################################################
# GEC with moogin/typix-grammar-large
# Optimized for A100 40GB
#########################################################

seed: 42

# Language Model
model_name: moogin/Typix-2.5
max_seq_length: 512
system_prompt: "You are a writing assistant that corrects errors in text. Follow the user's instruction exactly. Output only revised text."

# Dataset (HuggingFace)
dataset_name: moogin/typix-grpo
dataset_size: null  # use full dataset (already stratified)

# Training hyperparameters
learning_rate: 5.0e-6
warmup_steps: 50
max_steps: 550  # ~7 epochs (77 steps/epoch with batch=128)
gradient_accumulation_steps: 4  # effective batch = 128

# vLLM inference (A100 optimized)
per_device_train_batch_size: 32
num_generations: 16
generation_batch_size: 32
max_completion_length: 256
use_vllm: true
vllm_mode: "colocate"
vllm_gpu_memory_utilization: 0.4

# GRPO specific
beta: 0.04  # KL penalty
temperature: 1.1  # Sampling temperature for diverse generations

# Reward weights
greco_weight: 0.6
semantic_weight: 0.0
laziness_weight: 0.1
gain_epsilon: 0.005
reward_type: "ged"
gain_mode: "soft"
semantic_mode: "always"
semantic_drift_weight: 0.2
semantic_drift_threshold: 0.05
clean_edit_penalty: 0.05
ged_weight: 0.6

# Reward models (HuggingFace)
greco_model_name: mrqorib/grammaticality
mpnet_model: sentence-transformers/all-mpnet-base-v2
ged_model_name: gotutiyan/token-ged-electra-large-bin
ged_use_rate: true
ged_max_length: 128
ged_batch_size: 32

# LoRA configuration
use_peft: true
lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
lora_bias: "none"
use_rslora: false
lora_target_modules:
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"
  - "gate_proj"
  - "up_proj"
  - "down_proj"

# Experiment tracking
wandb_enabled: true
wandb_project_name: "gec-fine-tune-with-grpo"
logging_steps: 5
save_steps: 15  # ~5 checkpoints per epoch
save_total_limit: 30
push_to_hf: false
