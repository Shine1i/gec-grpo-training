#########################################################
# GEC with moogin/typix-grammar-large
# Optimized for A100 40GB
#########################################################

seed: 42

# Language Model
model_name: moogin/Typix-medium
max_seq_length: 512
system_prompt: "You are a writing assistant that edits text. Follow the user's instruction exactly. Preserve the original meaning unless the user asks to change it. Output only the revised text."

# Dataset (HuggingFace)
dataset_name: moogin/typix-hq-grannar
dataset_size: 10000  # 10k stratified sample

# Training hyperparameters
learning_rate: 5.0e-6
warmup_steps: 200
max_steps: 3750  # ~3 epochs with larger batch
gradient_accumulation_steps: 4  # effective batch = 64

# vLLM inference (A100 optimized)
per_device_train_batch_size: 8
num_generations: 8
generation_batch_size: 8
max_completion_length: 256
use_vllm: true
vllm_mode: "colocate"
vllm_gpu_memory_utilization: 0.4

# GRPO specific
beta: 0.04  # KL penalty
temperature: 1.1  # Sampling temperature for diverse generations

# Reward weights
greco_weight: 0.6
semantic_weight: 0.3
laziness_weight: 0.1

# Reward models (HuggingFace)
greco_model_name: mrqorib/grammaticality
mpnet_model: sentence-transformers/all-mpnet-base-v2

# LoRA configuration
use_peft: true
lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
lora_bias: "none"
use_rslora: false
lora_target_modules:
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"
  - "gate_proj"
  - "up_proj"
  - "down_proj"

# Experiment tracking
wandb_enabled: true
wandb_project_name: "gec-fine-tune-with-grpo"
logging_steps: 10
save_steps: 50
save_total_limit: 80
push_to_hf: false
